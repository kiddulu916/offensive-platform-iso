"""Advanced reconnaissance and exploitation workflow"""
from app.workflows.schemas import WorkflowDefinition, WorkflowTask, TaskType

def create_advanced_recon_exploit_workflow(domain: str) -> WorkflowDefinition:
    """
    Comprehensive automated penetration testing workflow:
    - Multi-tool subdomain enumeration with deduplication
    - IP extraction and high-speed port scanning
    - Service fingerprinting and exploit lookup
    - Directory enumeration and sensitive file detection
    - Web crawling for input fields
    - Automated SQL injection testing
    - Final JSON report aggregation
    """

    return WorkflowDefinition(
        workflow_id=f"advanced_recon_exploit_{domain}",
        name="Advanced Recon & Exploitation",
        description="Full-spectrum automated penetration test with intelligent exploitation",
        target=domain,
        tasks=[
            # ============================================================
            # Phase 1: Subdomain Enumeration
            # ============================================================

            WorkflowTask(
                task_id="enum_amass",
                name="Amass Enumeration (ASNs, IPs, Subdomains)",
                description="Deep reconnaissance with Amass for ASN/IP/subdomain discovery",
                tool="amass",
                parameters={
                    "domain": domain,
                    "passive": True
                },
                priority=10,
                timeout=900
            ),

            # Save Amass subdomains to file
            WorkflowTask(
                task_id="save_amass_subdomains",
                name="Save Amass Subdomains to File",
                task_type=TaskType.FILE_OUTPUT,
                parameters={
                    "source_task": "enum_amass",
                    "source_field": "subdomains",
                    "extract_field": "name",
                    "output_file": f"data/scans/{domain}/lists/subdomains_amass.txt"
                },
                depends_on=["enum_amass"],
                priority=9
            ),

            # Save Amass IPs to file
            WorkflowTask(
                task_id="save_amass_ips",
                name="Save Amass IPs to File",
                task_type=TaskType.FILE_OUTPUT,
                parameters={
                    "source_task": "enum_amass",
                    "source_field": "subdomains",
                    "extract_field": "ips",
                    "output_file": f"data/scans/{domain}/lists/ips_amass.txt"
                },
                depends_on=["enum_amass"],
                priority=9
            ),

            # Run Subfinder
            WorkflowTask(
                task_id="enum_subfinder",
                name="Subfinder Enumeration",
                tool="subfinder",
                parameters={
                    "domain": domain,
                    "all": True,
                    "resolve": True
                },
                priority=10,
                timeout=600
            ),

            # Run Sublist3r
            WorkflowTask(
                task_id="enum_sublist3r",
                name="Sublist3r Enumeration",
                tool="sublist3r",
                parameters={
                    "domain": domain,
                    "verbose": False
                },
                priority=10,
                timeout=600
            ),

            # Merge all subdomain sources
            WorkflowTask(
                task_id="merge_all_subdomains",
                name="Merge & Deduplicate All Subdomains",
                description="Combine Amass, Subfinder, Sublist3r results with IP merging",
                task_type=TaskType.MERGE,
                merge_sources=["enum_amass", "enum_subfinder", "enum_sublist3r"],
                merge_field="subdomains",
                dedupe_key="name",
                merge_strategy="combine",
                depends_on=["enum_amass", "enum_subfinder", "enum_sublist3r"],
                priority=8
            ),

            # Save final subdomain list
            WorkflowTask(
                task_id="save_final_subdomains",
                name="Save Final Subdomain List",
                task_type=TaskType.FILE_OUTPUT,
                parameters={
                    "source_task": "merge_all_subdomains",
                    "source_field": "merged_data",
                    "extract_field": "name",
                    "output_file": f"data/scans/{domain}/lists/subdomains_final.txt"
                },
                depends_on=["merge_all_subdomains"],
                priority=7
            ),

            # Extract all unique IPs
            WorkflowTask(
                task_id="save_final_ips",
                name="Save Final IP List",
                task_type=TaskType.FILE_OUTPUT,
                parameters={
                    "source_task": "merge_all_subdomains",
                    "source_field": "merged_data",
                    "extract_field": "ips",
                    "output_file": f"data/scans/{domain}/lists/ips_final.txt"
                },
                depends_on=["merge_all_subdomains"],
                priority=7
            ),

            # ============================================================
            # Phase 2: Port Scanning
            # ============================================================

            # Masscan on discovered IPs
            WorkflowTask(
                task_id="scan_masscan",
                name="Masscan Port & Service Discovery",
                description="High-speed port scan on all discovered IPs",
                tool="masscan",
                parameters={
                    "targets": "${merge_all_subdomains.merged_data}",  # Reference merged subdomain objects
                    "ports": "21,22,25,80,443,445,3306,3389,5432,8080,8443",
                    "rate": 10000
                },
                depends_on=["merge_all_subdomains"],
                priority=6,
                timeout=1800
            ),

            # ============================================================
            # Phase 3: Service Fingerprinting
            # ============================================================

            # Nmap service detection on open ports
            WorkflowTask(
                task_id="fingerprint_services",
                name="Nmap Service Version Detection",
                description="Detailed service fingerprinting for version numbers",
                tool="nmap",
                parameters={
                    "hosts": "${scan_masscan.hosts}",
                    "scan_type": "service_version",
                    "service_detection": True,
                    "version_intensity": 9
                },
                depends_on=["scan_masscan"],
                priority=5,
                timeout=3600
            ),

            # ============================================================
            # Phase 4: Exploit Lookup
            # ============================================================

            WorkflowTask(
                task_id="lookup_exploits",
                name="Exploit Database Lookup",
                description="Find exploits matching discovered service versions",
                task_type=TaskType.EXPLOIT_LOOKUP,
                parameters={
                    "source_task": "fingerprint_services",
                    "source_field": "services",
                    "include_experimental": False
                },
                depends_on=["fingerprint_services"],
                priority=6
            ),

            # Start final JSON aggregation
            WorkflowTask(
                task_id="aggregate_recon_results",
                name="Aggregate Reconnaissance Results",
                description="Create JSON report with all recon data",
                task_type=TaskType.JSON_AGGREGATE,
                parameters={
                    "output_file": f"data/scans/{domain}/results/recon_results.json",
                    "sections": [
                        {"name": "subdomains", "source_task": "merge_all_subdomains", "source_field": "merged_data"},
                        {"name": "ports", "source_task": "scan_masscan", "source_field": "hosts"},
                        {"name": "services", "source_task": "fingerprint_services", "source_field": "services"},
                        {"name": "exploits", "source_task": "lookup_exploits", "source_field": "matched_exploits"}
                    ]
                },
                depends_on=["lookup_exploits"],
                priority=5
            ),

            # ============================================================
            # Phase 5: Directory Enumeration
            # ============================================================

            WorkflowTask(
                task_id="enum_directories",
                name="FFUF Directory Enumeration",
                description="Discover directories on all subdomains",
                tool="ffuf",
                parameters={
                    "urls": "${merge_all_subdomains.merged_data}",
                    "wordlist": "/usr/share/wordlists/dirb/common.txt",
                    "extensions": "php,html,js,txt,xml,json",
                    "follow_redirects": True
                },
                depends_on=["merge_all_subdomains"],
                priority=5,
                timeout=3600
            ),

            # ============================================================
            # Phase 6: Web Crawling
            # ============================================================

            WorkflowTask(
                task_id="crawl_for_inputs",
                name="Crawl for Text Input Fields",
                description="Crawl all subdomains to find forms with text inputs",
                task_type=TaskType.WEB_CRAWL,
                parameters={
                    "source_task": "merge_all_subdomains",
                    "source_field": "merged_data",
                    "max_depth": 2,
                    "max_pages": 50,
                    "timeout": 10
                },
                depends_on=["merge_all_subdomains"],
                priority=4
            ),

            # Save pages with input fields
            WorkflowTask(
                task_id="save_input_pages",
                name="Save Input Field Pages List",
                task_type=TaskType.FILE_OUTPUT,
                parameters={
                    "source_task": "crawl_for_inputs",
                    "source_field": "pages_with_inputs",
                    "output_file": f"data/scans/{domain}/lists/pages_with_inputs.json",
                    "format": "json"
                },
                depends_on=["crawl_for_inputs"],
                priority=3
            ),

            # ============================================================
            # Phase 7: SQL Injection Testing
            # ============================================================

            WorkflowTask(
                task_id="test_sql_injection",
                name="SQLMap Automated Testing",
                description="Test all input field pages for SQL injection",
                tool="sqlmap",
                parameters={
                    "urls": "${crawl_for_inputs.pages_with_inputs}",
                    "batch": True,
                    "level": 2,
                    "risk": 2,
                    "forms": True
                },
                depends_on=["crawl_for_inputs"],
                priority=2,
                timeout=7200,
                optional=True  # Don't fail workflow if SQLMap fails
            ),

            # ============================================================
            # Phase 8: Final Aggregation
            # ============================================================

            WorkflowTask(
                task_id="final_json_report",
                name="Generate Final JSON Report",
                description="Aggregate all results into comprehensive report",
                task_type=TaskType.JSON_AGGREGATE,
                parameters={
                    "output_file": f"data/scans/{domain}/results/final_report.json",
                    "sections": [
                        {"name": "subdomains", "source_task": "merge_all_subdomains", "source_field": "merged_data"},
                        {"name": "ips", "source_task": "save_final_ips", "source_field": "items_written", "optional": True},
                        {"name": "ports", "source_task": "scan_masscan", "source_field": "hosts"},
                        {"name": "services", "source_task": "fingerprint_services", "source_field": "services"},
                        {"name": "exploits", "source_task": "lookup_exploits", "source_field": "matched_exploits"},
                        {"name": "directories", "source_task": "enum_directories", "source_field": "results", "optional": True},
                        {"name": "input_pages", "source_task": "crawl_for_inputs", "source_field": "pages_with_inputs"},
                        {"name": "sql_injection", "source_task": "test_sql_injection", "source_field": "findings", "optional": True},
                        {"name": "login_pages", "source_task": "crawl_for_inputs", "source_field": "login_pages", "optional": True}
                    ],
                    "include_metadata": True
                },
                depends_on=["aggregate_recon_results", "test_sql_injection"],
                priority=1
            )
        ],

        stop_on_failure=False,  # Continue even if some tasks fail
        max_parallel_tasks=1  # Sequential execution for safety
    )
